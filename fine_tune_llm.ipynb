{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hw9PbWOYxrZ8"
   },
   "source": [
    "## Steps to fine tune model\n",
    "- Select and load model\n",
    "- Select and preprocess dataset (train/eval split, tokenize)\n",
    "- Define quantization or adaptation before fine-tuning for efficiency\n",
    "- Tune and evaluate model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from transformers import Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
    "\n",
    "from datasets import load_dataset\n",
    "from peft import PeftModel\n",
    "from peft import prepare_model_for_kbit_training, LoraConfig, get_peft_model\n",
    "\n",
    "def initialize_model(hf_modelname, use_quantization=True):\n",
    "    \"\"\"Initialize the language model with quantization configuration for QLoRA.\"\"\"\n",
    "    if use_quantization:\n",
    "        bnb_config = BitsAndBytesConfig(\n",
    "            load_in_4bit=True,\n",
    "            bnb_4bit_use_double_quant=True,\n",
    "            bnb_4bit_quant_type=\"nf4\", # sets the data type for tuned parameters\n",
    "            bnb_4bit_compute_dtype=torch.bfloat16 # sets the data type for all parameters\n",
    "        )\n",
    "    else: \n",
    "        bnb_config = None\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(hf_modelname, device_map=\"auto\",\n",
    "                                                 quantization_config=bnb_config)\n",
    "    return model\n",
    "\n",
    "def initialize_tokenizer(hf_modelname):\n",
    "    \"\"\"Initialize the tokenizer.\"\"\"\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        hf_modelname,\n",
    "        padding_side=\"left\",\n",
    "        add_eos_token=True,\n",
    "        add_bos_token=True,\n",
    "        use_fast=False # when True this one uses a Rust-based tokenizer\n",
    "    )\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    return tokenizer\n",
    "\n",
    "\n",
    "def count_trainable_parameters(model):\n",
    "    \"\"\"Count the number of trainable parameters in the model.\"\"\"\n",
    "    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "    return params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/596 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00003.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.46k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/72.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hf_modelname = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "\n",
    "model = initialize_model(hf_modelname, use_quantization=True)\n",
    "tokenizer = initialize_tokenizer(hf_modelname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: True\n"
     ]
    }
   ],
   "source": [
    "print('GPU:', torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 7241732096\n",
      "Trainable parameters before LoRA: 262410240\n"
     ]
    }
   ],
   "source": [
    "print('Total parameters:', model.num_parameters())\n",
    "print('Trainable parameters before LoRA:', count_trainable_parameters(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_datasets(tokenizer, file_path):\n",
    "    \"\"\"Load and tokenize the training dataset.\"\"\"\n",
    "    dataset = load_dataset(path='text', data_files=file_path, split='train')\n",
    "    dataset = dataset.train_test_split(train_size=0.9)\n",
    "\n",
    "    # Shuffle the training dataset\n",
    "    dataset['train'] = dataset['train'].shuffle()\n",
    "\n",
    "    generate_and_tokenize_prompt = lambda prompt: tokenizer(prompt['text'])\n",
    "\n",
    "    tokenized_train_dataset = dataset['train'].map(generate_and_tokenize_prompt)\n",
    "    tokenized_val_dataset = dataset['test'].map(generate_and_tokenize_prompt)\n",
    "\n",
    "    return tokenized_train_dataset, tokenized_val_dataset\n",
    "\n",
    "\n",
    "def max_input_lengths(tokenized_train_dataset, tokenized_val_dataset):\n",
    "    lengths = [len(x['input_ids']) for x in tokenized_train_dataset] + \\\n",
    "              [len(x['input_ids']) for x in tokenized_val_dataset]\n",
    "\n",
    "    return max(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of longest input 201\n"
     ]
    }
   ],
   "source": [
    "tokenized_train_dataset, tokenized_val_dataset = prepare_datasets(tokenizer, 'data/finetune-emails.txt')\n",
    "print('Length of longest input', max_input_lengths(tokenized_train_dataset, tokenized_val_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_peft_model(model):\n",
    "    \"\"\"Setup PEFT (Parameter-Efficient Fine-Tuning) model.\"\"\"\n",
    "    model.gradient_checkpointing_enable()\n",
    "    model = prepare_model_for_kbit_training(model)\n",
    "    config = LoraConfig(\n",
    "        r=32,\n",
    "        lora_alpha=64,\n",
    "        target_modules=[\n",
    "            \"q_proj\",\n",
    "            \"k_proj\",\n",
    "            \"v_proj\",\n",
    "            \"gate_proj\",\n",
    "            \"up_proj\",\n",
    "            \"down_proj\",\n",
    "        ],\n",
    "        bias=\"none\",\n",
    "        lora_dropout=0.05,\n",
    "        task_type=\"CAUSAL_LM\",\n",
    "    )\n",
    "    model = get_peft_model(model, config)\n",
    "    return model\n",
    "    \n",
    "def configure_model(model):\n",
    "    \"\"\"Configure model for parallelism.\"\"\"\n",
    "    if torch.cuda.device_count() > 1: \n",
    "        model.is_parallelizable = True\n",
    "        model.model_parallel = True\n",
    "\n",
    "def initialize_trainer(model, train_dataset, eval_dataset, run_name):\n",
    "    \"\"\"Initialize the Trainer for training.\"\"\"\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"./\" + run_name,\n",
    "        gradient_checkpointing=True, # save memory\n",
    "        num_train_epochs=2, # 2 epochs should be enough but good to tune further\n",
    "        learning_rate=1e-5, # small learning rate for fine tuning\n",
    "        bf16=True, # since we're using quantization\n",
    "        optim=\"paged_adamw_8bit\", # setting it here allows to fit in memory for fine tuning still\n",
    "        per_device_train_batch_size=64,\n",
    "        per_device_eval_batch_size=64,\n",
    "        logging_steps=25,\n",
    "        save_steps=100,\n",
    "        eval_steps=100,\n",
    "        logging_dir=\"./logs\",\n",
    "        save_strategy=\"steps\",\n",
    "        evaluation_strategy=\"steps\",\n",
    "        do_eval=True,\n",
    "    )\n",
    "\n",
    "    data_collator = DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        args=training_args,\n",
    "        data_collator=data_collator,\n",
    "    )\n",
    "    return trainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How does model perform BEFORE fine-tuning?\n",
      "<s> [INST]Give me an email-only content calendar for activating users that haven't used my service in more than 3 months.\n",
      "  The service is an online marketplace for prospective home buyers to find houses and apartments in the Netherlands.\n",
      "  Instructions: for each content idea provided, give me why this is something that makes sense for activating dormant users,\n",
      "  and how to adjust the content strategy depending on whether it has been successful at activating the user after each month.\n",
      "  [/INST]</s> 1. **Welcome Back Email (Month 1)**\n",
      "   * Reason: Welcome back email is a classic and effective way to re-engage dormant users. It's a friendly reminder that they have an account with your service and that you value their presence.\n",
      "   * Content: Personalized message, a brief update on new features or improvements, and a call-to-action to log back in and explore the platform.\n",
      "   * Strategy: Monitor open and click-through rates. If successful, follow up with a more targeted email in the next month.\n",
      "\n",
      "2. **Property Recommendations (Month 1-3)**\n",
      "   * Reason: Dormant users may have saved properties in their account or have specific preferences. Sending them personalized recommendations can re-engage them and remind them of the value of your service.\n",
      "   * Content: Personalized email with a few property recommendations based on their past searches and preferences.\n",
      "   * Strategy: Monitor open and click-through rates. If successful, increase the frequency of these emails or add more personalized recommendations based on their browsing history.\n",
      "\n",
      "3. **Educational Content (Month 2-3)**\n",
      "   * Reason: Educational content can help users understand the benefits of your service and how it can help them in their home buying journey.\n",
      "   * Content: Send a series of educational emails covering topics like the home buying process, neighborhood guides, and market trends.\n",
      "   * Strategy: Monitor open and click-through rates. If successful, continue sending educational content and consider offering webinars or live Q&A sessions.\n",
      "\n",
      "4. **Exclusive Offers (Month 3)**\n",
      "   * Reason: Offering exclusive deals or discounts can be a powerful incentive to re-engage dormant users and encourage them to take action.\n",
      "   * Content: Send an email with exclusive offers or discounts on properties or services.\n",
      "   * Strategy: Monitor open and click-through rates. If successful, consider sending more frequent emails with exclusive offers or creating a loyalty program.\n",
      "\n",
      "5. **Personalized Neighborhood Guides (Month 3)**\n",
      "   * Reason: Dormant users may be interested in specific neighborhoods but haven't found the right property yet. Sending them personalized neighborhood guides can help them make an informed decision.\n",
      "   * Content: Send an email with a personalized neighborhood guide, including information on amenities, schools, and local attractions.\n",
      "   * Strategy: Monitor open and click-through rates. If successful, continue sending personalized neighborhood guides and consider offering virtual tours or in-person tours.\n",
      "\n",
      "6. **Re-engagement Campaigns (Month 3-6)**\n",
      "   * Reason: If a user hasn't engaged with your emails after three months, it may be time to try a more aggressive re-engagement campaign.\n",
      "   * Content: Send a series of emails with increasingly personalized and targeted content, including offers, incentives, and reminders of the benefits of your service.\n",
      "   * Strategy: Monitor open and click-through rates. If successful, continue sending re-engagement emails and consider offering a personalized consultation or consultation call.\n",
      "\n",
      "7. **Referral Program (Month 6)**\n",
      "   * Reason: Referral programs can be an effective way to re-engage dormant users and acquire new customers.\n",
      "   * Content: Send an email introducing your referral program and offering incentives for referring new users.\n",
      "   * Strategy: Monitor open and click-through rates. If successful, continue sending referral program emails and consider offering additional incentives or rewards.</s>\n"
     ]
    }
   ],
   "source": [
    "print('How does model perform BEFORE fine-tuning?')\n",
    "\n",
    "inputs = tokenizer(\"\"\"[INST]Give me an email-only content calendar for activating users that haven't used my service in more than 3 months.\n",
    "  The service is an online marketplace for prospective home buyers to find houses and apartments in the Netherlands.\n",
    "  Instructions: for each content idea provided, give me why this is something that makes sense for activating dormant users,\n",
    "  and how to adjust the content strategy depending on whether it has been successful at activating the user after each month.\n",
    "  [/INST]\"\"\",\n",
    "                   return_tensors=\"pt\", return_attention_mask=False).to(\"cuda\")\n",
    "outputs = model.generate(**inputs, max_length=4096 - inputs['input_ids'].shape[1])\n",
    "text = tokenizer.batch_decode(outputs)[0]\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1.0317767305015078\n"
     ]
    }
   ],
   "source": [
    "model = setup_peft_model(model)\n",
    "print(f'trainable params: {100 * count_trainable_parameters(model) / model.num_parameters()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.use_cache = False\n",
    "\n",
    "run_name = \"mistral-7b-it-emails\"\n",
    "\n",
    "trainer = initialize_trainer(model, tokenized_train_dataset, tokenized_val_dataset, run_name)\n",
    "trainer.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "Memory consumption notes \n",
    "\n",
    "With QLoRA: \n",
    "- Idle: 5500MB\n",
    "- Inference: 6600MB\n",
    "- Finetuning batch size 64: 20200MB\n",
    "\n",
    "Without quantization: \n",
    "- Idle: 29086MiB\n",
    "- Inference: 29776MiB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('How does model perform AFTER fine-tuning?')\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "model = initialize_model(hf_modelname)\n",
    "tokenizer = initialize_tokenizer(hf_modelname)\n",
    "\n",
    "for i in range(100, 1000, 100):\n",
    "    checkpoint_name = f\"{run_name}/checkpoint-{i}\"\n",
    "    ft_model = PeftModel.from_pretrained(model, checkpoint_name)\n",
    "\n",
    "    inputs = tokenizer(\"\"\"[INST]Give me an email-only content calendar for activating users that haven't used my service in more than 3 months.\n",
    "          The service is an online marketplace for prospective home buyers to find houses and apartments in the Netherlands.\n",
    "          Instructions: for each content idea provided, give me why this is something that makes sense for activating dormant users,\n",
    "          and how to adjust the content strategy depending on whether it has been successful at activating the user after each month.\n",
    "          [/INST]\"\"\",\n",
    "        return_tensors=\"pt\", return_attention_mask=False).to(\"cuda\")\n",
    "\n",
    "    outputs = ft_model.generate(**inputs, max_length=4096 - inputs['input_ids'].shape[1])\n",
    "    text = tokenizer.batch_decode(outputs)[0]\n",
    "    print(checkpoint_name)\n",
    "    print(text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_modelname = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "run_name = \"mistral-7b-it-emails\"\n",
    "checkpoint_name = f\"{run_name}/checkpoint-900\"\n",
    "\n",
    "model = initialize_model(hf_modelname, use_quantization=True)\n",
    "tokenizer = initialize_tokenizer(hf_modelname)\n",
    "ft_model = PeftModel.from_pretrained(model, checkpoint_name)\n",
    "\n",
    "\n",
    "ft_model = ft_model.merge_and_unload()\n",
    "\n",
    "# # Publish the new model to Hugging Face Hub\n",
    "# model.push_to_hub(run_name, use_temp_dir=False)\n",
    "# tokenizer.push_to_hub(run_name, use_temp_dir=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/peft/tuners/lora/bnb.py:272: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "ft_model = ft_model.merge_and_unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bae7f58d86a344beaca253b60766bffd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/4.13G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0b69e386cca48dd8abdd59b64a45afb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee6183b183fd4025ad40d19aee200c04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/azamatomu/mistral-7b-it-emails/commit/8974209ed3eaa70421ac8f3677cfb9cf579608f8', commit_message='Upload tokenizer', commit_description='', oid='8974209ed3eaa70421ac8f3677cfb9cf579608f8', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub(run_name, use_temp_dir=False, token=access_token)\n",
    "tokenizer.push_to_hub(run_name, use_temp_dir=False, token=access_token)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wqFGf9Ak9jFT"
   },
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZYRbi8UM1pa5",
    "outputId": "52131dcf-b80f-4a5e-889f-404c2e9bf34a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q accelerate transformers peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H4b__4hz3E5c",
    "outputId": "fefc7eb7-e378-421b-edf8-0b25036ff823"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q datasets scipy ipywidgets matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R2C59WTv68VR",
    "outputId": "e43e8cfc-2fe7-4cc4-b98e-86bda2258134"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accelerate==0.27.2\n",
    "bitsandbytes==0.42.0\n",
    "datasets==2.17.1\n",
    "ipywidgets==8.1.1\n",
    "matplotlib==3.8.3\n",
    "peft==0.9.0\n",
    "scipy==1.12.0\n",
    "sentencepiece==0.2.0\n",
    "transformers==4.38.1\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "05849d81ea3c476399fa16ed04df701e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "08d4c699bdac443cb2696a9016bab802": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cef43065c0cd4a58b04212cefd61106c",
      "placeholder": "​",
      "style": "IPY_MODEL_c200736bc07e4c35a95e8a923e225d28",
      "value": " 30132/30132 [00:15&lt;00:00, 2163.66 examples/s]"
     }
    },
    "11c77b811e0745569b4dc40685f71b6e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1a66559c14b14e86ac3e38581c87d773": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bf091b6addf846bf881bdddcaa1d292f",
       "IPY_MODEL_9ff5bf96034e4982be9a296658e18b28",
       "IPY_MODEL_08d4c699bdac443cb2696a9016bab802"
      ],
      "layout": "IPY_MODEL_48c3a62fa47a404ea92e1c17fc7b50eb"
     }
    },
    "1f2c71bf1e9348518fae1c087ffe1b72": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_905184dcef1f4df1b8568a6aa8d1882c",
      "placeholder": "​",
      "style": "IPY_MODEL_cb334193ef184a80ac76acafc42e9e15",
      "value": "Map: 100%"
     }
    },
    "27b71e0556d84b62ab024d6df25f5422": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "295cc2482da0441080cc3404f488d09c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_05849d81ea3c476399fa16ed04df701e",
      "max": 3349,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_11c77b811e0745569b4dc40685f71b6e",
      "value": 3349
     }
    },
    "36f6e9448580497bbfb47b2dde1e2bf4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3bcbf7ccbecb4b6aab73017ec7c6da05": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_75756ad6cd8c4556beb9bb1f36da3c84",
      "placeholder": "​",
      "style": "IPY_MODEL_5d792d0310e94385bd150658adf60c34",
      "value": " 3349/3349 [00:01&lt;00:00, 1912.59 examples/s]"
     }
    },
    "48c3a62fa47a404ea92e1c17fc7b50eb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5d792d0310e94385bd150658adf60c34": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5f462014cb824dea9bec2ae36f7f01ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1f2c71bf1e9348518fae1c087ffe1b72",
       "IPY_MODEL_295cc2482da0441080cc3404f488d09c",
       "IPY_MODEL_3bcbf7ccbecb4b6aab73017ec7c6da05"
      ],
      "layout": "IPY_MODEL_661fa7e195d844a482a212be4c4ee79c"
     }
    },
    "661fa7e195d844a482a212be4c4ee79c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "72bb036a5c264621b85589199debd8cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "75756ad6cd8c4556beb9bb1f36da3c84": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "905184dcef1f4df1b8568a6aa8d1882c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9ff5bf96034e4982be9a296658e18b28": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c2c7d284450841259db296c370886281",
      "max": 30132,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_36f6e9448580497bbfb47b2dde1e2bf4",
      "value": 30132
     }
    },
    "bf091b6addf846bf881bdddcaa1d292f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_27b71e0556d84b62ab024d6df25f5422",
      "placeholder": "​",
      "style": "IPY_MODEL_72bb036a5c264621b85589199debd8cf",
      "value": "Map: 100%"
     }
    },
    "c200736bc07e4c35a95e8a923e225d28": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c2c7d284450841259db296c370886281": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cb334193ef184a80ac76acafc42e9e15": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cef43065c0cd4a58b04212cefd61106c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
