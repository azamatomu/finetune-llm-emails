{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hw9PbWOYxrZ8"
   },
   "source": [
    "## Steps to fine tune model\n",
    "- Select and load model\n",
    "- Select and preprocess dataset (train/eval split, tokenize)\n",
    "- Define quantization or adaptation before fine-tuning for efficiency\n",
    "- Tune and evaluate model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wqFGf9Ak9jFT"
   },
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZYRbi8UM1pa5",
    "outputId": "52131dcf-b80f-4a5e-889f-404c2e9bf34a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q accelerate transformers peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H4b__4hz3E5c",
    "outputId": "fefc7eb7-e378-421b-edf8-0b25036ff823"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q datasets scipy ipywidgets matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R2C59WTv68VR",
    "outputId": "e43e8cfc-2fe7-4cc4-b98e-86bda2258134"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 775
    },
    "id": "SlG_g0CzyxqI",
    "outputId": "ac9989de-ed74-4eb2-bbc9-40b49a3da90b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "205f8a5f05304d03aac25fd60e849148",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import accelerate\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "access_token = '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'\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    "    # bnb_4bit_compute_dtype=torch.float16\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"google/gemma-2b-it\", device_map=\"auto\",\n",
    "                                             quantization_config=bnb_config,\n",
    "                                            #  torch_dtype=torch.float16, load_in_8bit=True,\n",
    "                                             token=access_token)\n",
    "# tokenizer = AutoTokenizer.from_pretrai\\ned(\"microsoft/phi-2\")#, trust_remote_code=True)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"google/gemma-2b-it\",\n",
    "    padding_side=\"left\",\n",
    "    add_eos_token=True,\n",
    "    add_bos_token=True,\n",
    "    use_fast=False,\n",
    "    token=access_token\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vjsBRZo8zvjQ",
    "outputId": "b70769da-814f-4316-89da-ce2d35a6ae2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2506172416"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available(), model.device)\n",
    "model.num_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gk8GS4gWA5_C",
    "outputId": "e7e1b282-93b1-49ff-e07a-a349bf786eae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "524363776"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def count_trainable_parameters(model):\n",
    "    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "    return params\n",
    "count_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "G3iNGsoQtA_E"
   },
   "outputs": [],
   "source": [
    "import locale\n",
    "locale.getpreferredencoding = lambda: \"UTF-8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p0P-Y9Sw7Odu",
    "outputId": "bb0dc033-56f7-45fa-b982-8d317dbcfee0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Feb 29 08:54:10 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.104.12             Driver Version: 535.104.12   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA RTX 4000 Ada Gene...    On  | 00000000:C2:00.0 Off |                  Off |\n",
      "| 30%   36C    P8              11W / 130W |  10239MiB / 20475MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-ZRUreX27p_F",
    "outputId": "01262e61-bef2-41c3-9f4c-7bc77bddb6cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos>\n",
      "  Give me an email-only content calendar for activating users that haven't used my service in more than 3 months.\n",
      "  The service is an online marketplace for prospective home buyers to find houses and apartments in the Netherlands.\n",
      "  Instructions: for each content idea provided, give me why this is something that makes sense for activating dormant users,\n",
      "  and how to adjust the content strategy depending on whether it has been successful at activating the user after each month.\n",
      "<eos>**Email Sequence for Activating Dormant Users**\n",
      "\n",
      "**Month 1:**\n",
      "\n",
      "* **Subject:** Discover the Perfect Home in the Netherlands!\n",
      "* **Content:** A personalized welcome email with a special offer for new users, such as a free property search or a discount on their first purchase.\n",
      "* **Success:** This email sequence has a high open rate and encourages new users to explore the platform.\n",
      "\n",
      "**Month 2:**\n",
      "\n",
      "* **Subject:** Your Home Search is Heating Up!\n",
      "* **Content:** A series of emails showcasing new listings and updates to keep users engaged.\n",
      "* **Success:** This email sequence provides valuable information and keeps users interested in the platform.\n",
      "\n",
      "**Month 3:**\n",
      "\n",
      "* **Subject:** Don't Miss Out! Exclusive Offer for Returning Users\n",
      "* **Content:** A personalized email with a limited-time discount or promotion for returning users.\n",
      "* **Success:** This email sequence encourages users to return and take advantage of the special offer.\n",
      "\n",
      "**Month 4:**\n",
      "\n",
      "* **Subject:** We Miss You! Welcome Back!\n",
      "* **Content:** A welcome email with a personalized message and a reminder of the value the platform offers.\n",
      "* **Success:** This email sequence reengages dormant users and encourages them to explore the platform again.\n",
      "\n",
      "**Month 5:**\n",
      "\n",
      "* **Subject:** Discover the Benefits of Our Exclusive Services\n",
      "* **Content:** A comprehensive email outlining the unique benefits and services offered by the platform.\n",
      "* **Success:** This email sequence provides valuable information and convinces dormant users to sign up for a premium membership.\n",
      "\n",
      "**Month 6:**\n",
      "\n",
      "* **Subject:** It's Time to Find Your Dream Home!\n",
      "* **Content:** A personalized email with a curated selection of properties that match the user's preferences.\n",
      "* **Success:** This email sequence provides a sense of urgency and encourages users to complete their purchase.<eos>\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(\"\"\"\n",
    "  Give me an email-only content calendar for activating users that haven't used my service in more than 3 months.\n",
    "  The service is an online marketplace for prospective home buyers to find houses and apartments in the Netherlands.\n",
    "  Instructions: for each content idea provided, give me why this is something that makes sense for activating dormant users,\n",
    "  and how to adjust the content strategy depending on whether it has been successful at activating the user after each month.\n",
    "\"\"\",\n",
    "                   return_tensors=\"pt\", return_attention_mask=False).to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(**inputs, max_length=500)\n",
    "text = tokenizer.batch_decode(outputs)[0]\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "d4_e7WOi2p6s"
   },
   "outputs": [],
   "source": [
    "# with open('finetune-emails.txt', 'r') as file:\n",
    "#     text = ''.join([row for row in file.readlines() if row != '\\n'])\n",
    "# with open('sadyr_preprocessed.txt', 'w') as file:\n",
    "#     file.write(text)\n",
    "\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(path='text', data_files='finetune-emails.txt', split='train')\n",
    "dataset = dataset.train_test_split(train_size=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1YGB8EZ9AYY7",
    "outputId": "c53417bc-105a-4989-94e0-ed78798a2e98"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['text'],\n",
       "     num_rows: 30132\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['text'],\n",
       "     num_rows: 3349\n",
       " }))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'], dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "1a66559c14b14e86ac3e38581c87d773",
      "bf091b6addf846bf881bdddcaa1d292f",
      "9ff5bf96034e4982be9a296658e18b28",
      "08d4c699bdac443cb2696a9016bab802",
      "48c3a62fa47a404ea92e1c17fc7b50eb",
      "27b71e0556d84b62ab024d6df25f5422",
      "72bb036a5c264621b85589199debd8cf",
      "c2c7d284450841259db296c370886281",
      "36f6e9448580497bbfb47b2dde1e2bf4",
      "cef43065c0cd4a58b04212cefd61106c",
      "c200736bc07e4c35a95e8a923e225d28",
      "5f462014cb824dea9bec2ae36f7f01ad",
      "1f2c71bf1e9348518fae1c087ffe1b72",
      "295cc2482da0441080cc3404f488d09c",
      "3bcbf7ccbecb4b6aab73017ec7c6da05",
      "661fa7e195d844a482a212be4c4ee79c",
      "905184dcef1f4df1b8568a6aa8d1882c",
      "cb334193ef184a80ac76acafc42e9e15",
      "05849d81ea3c476399fa16ed04df701e",
      "11c77b811e0745569b4dc40685f71b6e",
      "75756ad6cd8c4556beb9bb1f36da3c84",
      "5d792d0310e94385bd150658adf60c34"
     ]
    },
    "id": "rR2_x3G8ALfi",
    "outputId": "5fe0b580-107d-41b6-9a23-22b8f1a4848c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2793a8701d543ac9fdbdc2904cb2679",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/30132 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2441cd5a1100497d965eac02d6bc8c4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3349 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generate_and_tokenize_prompt = lambda prompt: tokenizer(prompt['text'])\n",
    "\n",
    "tokenized_train_dataset = dataset['train'].map(generate_and_tokenize_prompt)\n",
    "tokenized_val_dataset = dataset['test'].map(generate_and_tokenize_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 582
    },
    "id": "MC7quQviA-3G",
    "outputId": "12c943f5-be52-42fc-ea89-68765bb521ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33481\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_data_lengths(tokenized_train_dataset, tokenized_val_dataset):\n",
    "    lengths = [len(x['input_ids']) for x in tokenized_train_dataset]\n",
    "    lengths += [len(x['input_ids']) for x in tokenized_val_dataset]\n",
    "    print(len(lengths))\n",
    "\n",
    "    # Plotting the histogram\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(lengths, bins=20, alpha=0.7, color='blue')\n",
    "    plt.xlabel('Length of input_ids')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Distribution of Lengths of input_ids')\n",
    "    plt.show()\n",
    "\n",
    "plot_data_lengths(tokenized_train_dataset, tokenized_val_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "KE58ylPYA_h3"
   },
   "outputs": [],
   "source": [
    "from peft import prepare_model_for_kbit_training\n",
    "\n",
    "model.gradient_checkpointing_enable()\n",
    "model = prepare_model_for_kbit_training(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gy8GfYh9IQn9",
    "outputId": "9b3d5eec-3b76-417a-b449-46dbbd1510a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GemmaForCausalLM(\n",
      "  (model): GemmaModel(\n",
      "    (embed_tokens): Embedding(256000, 2048, padding_idx=0)\n",
      "    (layers): ModuleList(\n",
      "      (0-17): 18 x GemmaDecoderLayer(\n",
      "        (self_attn): GemmaAttention(\n",
      "          (q_proj): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
      "          (k_proj): Linear4bit(in_features=2048, out_features=256, bias=False)\n",
      "          (v_proj): Linear4bit(in_features=2048, out_features=256, bias=False)\n",
      "          (o_proj): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
      "          (rotary_emb): GemmaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): GemmaMLP(\n",
      "          (gate_proj): Linear4bit(in_features=2048, out_features=16384, bias=False)\n",
      "          (up_proj): Linear4bit(in_features=2048, out_features=16384, bias=False)\n",
      "          (down_proj): Linear4bit(in_features=16384, out_features=2048, bias=False)\n",
      "          (act_fn): GELUActivation()\n",
      "        )\n",
      "        (input_layernorm): GemmaRMSNorm()\n",
      "        (post_attention_layernorm): GemmaRMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): GemmaRMSNorm()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=2048, out_features=256000, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "L-BDW0myBNog"
   },
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "config = LoraConfig(\n",
    "    r=32,\n",
    "    lora_alpha=64,\n",
    "    target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"k_proj\",\n",
    "        \"v_proj\",\n",
    "        # \"dense\",\n",
    "        \"gate_proj\",\n",
    "        \"up_proj\",\n",
    "        \"down_proj\",\n",
    "    ],\n",
    "    bias=\"none\",\n",
    "    lora_dropout=0.05,  # Conventional\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, config)\n",
    "# print_trainable_parameters(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "1ysNNsIFBTQV",
    "outputId": "89f5c35d-d9eb-41cd-9511-4b02e30f2cf0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'trainable params: 1.449605666991754'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'trainable params: {100 * count_trainable_parameters(model) / model.num_parameters()}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "OsOydCvMDjIT"
   },
   "outputs": [],
   "source": [
    "from accelerate import FullyShardedDataParallelPlugin, Accelerator\n",
    "from torch.distributed.fsdp.fully_sharded_data_parallel import FullOptimStateDictConfig, FullStateDictConfig\n",
    "\n",
    "fsdp_plugin = FullyShardedDataParallelPlugin(\n",
    "    state_dict_config=FullStateDictConfig(offload_to_cpu=True, rank0_only=False),\n",
    "    optim_state_dict_config=FullOptimStateDictConfig(offload_to_cpu=True, rank0_only=False),\n",
    ")\n",
    "\n",
    "accelerator = Accelerator(fsdp_plugin=fsdp_plugin)\n",
    "model = accelerator.prepare_model(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 555
    },
    "id": "b-zP3fSsBfgN",
    "outputId": "ac5c246e-8e5f-4809-95ab-4e66fa9b268c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3504' max='5652' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3504/5652 58:32 < 35:54, 1.00 it/s, Epoch 1.86/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.716900</td>\n",
       "      <td>1.675079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.445700</td>\n",
       "      <td>1.577618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.436500</td>\n",
       "      <td>1.522319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/peft/utils/other.py:588: UserWarning: Unable to fetch remote file due to the following error 401 Client Error. (Request ID: Root=1-65e04c68-758f3c3540b44c460e1ab766;faa33f2e-c0da-4569-a131-d0bffcd1f91e)\n",
      "\n",
      "Cannot access gated repo for url https://huggingface.co/google/gemma-2b-it/resolve/main/config.json.\n",
      "Repo model google/gemma-2b-it is gated. You must be authenticated to access it. - silently ignoring the lookup for the file config.json in google/gemma-2b-it.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in google/gemma-2b-it - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/peft/utils/other.py:588: UserWarning: Unable to fetch remote file due to the following error 401 Client Error. (Request ID: Root=1-65e05064-46eeb96a2257ccaa1b5edfa0;039d8fae-d46b-4e54-a238-08c0d493a80d)\n",
      "\n",
      "Cannot access gated repo for url https://huggingface.co/google/gemma-2b-it/resolve/main/config.json.\n",
      "Repo model google/gemma-2b-it is gated. You must be authenticated to access it. - silently ignoring the lookup for the file config.json in google/gemma-2b-it.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in google/gemma-2b-it - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/peft/utils/other.py:588: UserWarning: Unable to fetch remote file due to the following error 401 Client Error. (Request ID: Root=1-65e05455-5852bb8708ae97ba24bd39b2;aad8c46e-7817-459c-ad29-3279ed54cf9f)\n",
      "\n",
      "Cannot access gated repo for url https://huggingface.co/google/gemma-2b-it/resolve/main/config.json.\n",
      "Repo model google/gemma-2b-it is gated. You must be authenticated to access it. - silently ignoring the lookup for the file config.json in google/gemma-2b-it.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in google/gemma-2b-it - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 2.53 GiB. GPU 0 has a total capacty of 19.68 GiB of which 356.00 MiB is free. Process 2315963 has 19.20 GiB memory in use. Of the allocated memory 14.02 GiB is allocated by PyTorch, and 4.98 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 47\u001b[0m\n\u001b[1;32m     14\u001b[0m trainer \u001b[38;5;241m=\u001b[39m transformers\u001b[38;5;241m.\u001b[39mTrainer(\n\u001b[1;32m     15\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     16\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mtokenized_train_dataset,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     43\u001b[0m     data_collator\u001b[38;5;241m=\u001b[39mtransformers\u001b[38;5;241m.\u001b[39mDataCollatorForLanguageModeling(tokenizer, mlm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m     44\u001b[0m )\n\u001b[1;32m     46\u001b[0m model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# silence the warnings. Please re-enable for inference!\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:1624\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1622\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1623\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1624\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1625\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1626\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1627\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1628\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1629\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:1961\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1958\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   1960\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 1961\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1963\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1964\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1965\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1966\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1967\u001b[0m ):\n\u001b[1;32m   1968\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1969\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:2902\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   2901\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 2902\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2904\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mn_gpu \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   2905\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mmean()  \u001b[38;5;66;03m# mean() to average on multi-gpu parallel training\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:2925\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2923\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2924\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2925\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2926\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   2927\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   2928\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/operations.py:817\u001b[0m, in \u001b[0;36mconvert_outputs_to_fp32.<locals>.forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 817\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/operations.py:805\u001b[0m, in \u001b[0;36mConvertOutputsToFp32.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconvert_to_fp32\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/operations.py:784\u001b[0m, in \u001b[0;36mconvert_to_fp32\u001b[0;34m(tensor)\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_is_fp16_bf16_tensor\u001b[39m(tensor):\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(tensor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01min\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39mfloat16, torch\u001b[38;5;241m.\u001b[39mbfloat16)\n\u001b[0;32m--> 784\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrecursively_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_convert_to_fp32\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_is_fp16_bf16_tensor\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/operations.py:127\u001b[0m, in \u001b[0;36mrecursively_apply\u001b[0;34m(func, data, test_type, error_on_other_type, *args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m honor_type(\n\u001b[1;32m    117\u001b[0m         data,\n\u001b[1;32m    118\u001b[0m         (\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    123\u001b[0m         ),\n\u001b[1;32m    124\u001b[0m     )\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, Mapping):\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(data)(\n\u001b[0;32m--> 127\u001b[0m         {\n\u001b[1;32m    128\u001b[0m             k: recursively_apply(\n\u001b[1;32m    129\u001b[0m                 func, v, \u001b[38;5;241m*\u001b[39margs, test_type\u001b[38;5;241m=\u001b[39mtest_type, error_on_other_type\u001b[38;5;241m=\u001b[39merror_on_other_type, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    130\u001b[0m             )\n\u001b[1;32m    131\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    132\u001b[0m         }\n\u001b[1;32m    133\u001b[0m     )\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m test_type(data):\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(data, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/operations.py:128\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m honor_type(\n\u001b[1;32m    117\u001b[0m         data,\n\u001b[1;32m    118\u001b[0m         (\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    123\u001b[0m         ),\n\u001b[1;32m    124\u001b[0m     )\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, Mapping):\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(data)(\n\u001b[1;32m    127\u001b[0m         {\n\u001b[0;32m--> 128\u001b[0m             k: \u001b[43mrecursively_apply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_on_other_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_on_other_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    132\u001b[0m         }\n\u001b[1;32m    133\u001b[0m     )\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m test_type(data):\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(data, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/operations.py:135\u001b[0m, in \u001b[0;36mrecursively_apply\u001b[0;34m(func, data, test_type, error_on_other_type, *args, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(data)(\n\u001b[1;32m    127\u001b[0m         {\n\u001b[1;32m    128\u001b[0m             k: recursively_apply(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    132\u001b[0m         }\n\u001b[1;32m    133\u001b[0m     )\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m test_type(data):\n\u001b[0;32m--> 135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m error_on_other_type:\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    138\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported types (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) passed to `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`. Only nested list/tuple/dicts of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    139\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjects that are valid for `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_type\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` should be passed.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    140\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/operations.py:779\u001b[0m, in \u001b[0;36mconvert_to_fp32.<locals>._convert_to_fp32\u001b[0;34m(tensor)\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_convert_to_fp32\u001b[39m(tensor):\n\u001b[0;32m--> 779\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 2.53 GiB. GPU 0 has a total capacty of 19.68 GiB of which 356.00 MiB is free. Process 2315963 has 19.20 GiB memory in use. Of the allocated memory 14.02 GiB is allocated by PyTorch, and 4.98 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "if torch.cuda.device_count() > 1: # If more than 1 GPU\n",
    "    model.is_parallelizable = True\n",
    "    model.model_parallel = True\n",
    "\n",
    "\n",
    "import transformers\n",
    "from datetime import datetime\n",
    "\n",
    "project = \"emails\"\n",
    "base_model_name = \"gemma-2-it\"\n",
    "run_name = base_model_name + \"-\" + project\n",
    "output_dir = \"./\" + run_name\n",
    "\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_val_dataset,\n",
    "    args=transformers.TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        warmup_steps=1,\n",
    "        # per_device_train_batch_size=2,\n",
    "        gradient_accumulation_steps=1,\n",
    "        gradient_checkpointing=True,\n",
    "        # max_steps=500,\n",
    "        num_train_epochs=3,\n",
    "        learning_rate=2.5e-5, # Want a small lr for finetuning\n",
    "        bf16=True,\n",
    "        # fp16=True,\n",
    "        optim=\"paged_adamw_8bit\",\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=16,\n",
    "        # optim=\"paged_adamw_32bit\",\n",
    "        logging_steps=25,              # When to start reporting loss\n",
    "        logging_dir=\"./logs\",        # Directory for storing logs\n",
    "        save_strategy=\"steps\",       # Save the model checkpoint every logging step\n",
    "        save_steps=1000,                # Save checkpoints every 50 steps\n",
    "        evaluation_strategy=\"steps\", # Evaluate the model every logging step\n",
    "        eval_steps=1000,               # Evaluate and save checkpoints every 50 steps\n",
    "        do_eval=True,                # Perform evaluation at the end of training\n",
    "        # report_to=\"wandb\",           # Comment this out if you don't want to use weights & baises\n",
    "        # run_name=f\"{run_name}-{datetime.now().strftime('%Y-%m-%d-%H-%M')}\"          # Name of the W&B run (optional)\n",
    "    ),\n",
    "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    ")\n",
    "\n",
    "model.config.use_cache = False  # silence the warnings. Please re-enable for inference!\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Feb 29 10:05:25 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.104.12             Driver Version: 535.104.12   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA RTX 4000 Ada Gene...    On  | 00000000:C2:00.0 Off |                  Off |\n",
      "| 30%   40C    P8              11W / 130W |  19797MiB / 20475MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96f3e527ed2b4027bdf69544039fa231",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import accelerate\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "access_token = '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'\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    "    # bnb_4bit_compute_dtype=torch.float16\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"google/gemma-2b-it\", device_map=\"auto\",\n",
    "                                             quantization_config=bnb_config,\n",
    "                                            #  torch_dtype=torch.float16, load_in_8bit=True,\n",
    "                                             token=access_token)\n",
    "# tokenizer = AutoTokenizer.from_pretrai\\ned(\"microsoft/phi-2\")#, trust_remote_code=True)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"google/gemma-2b-it\",\n",
    "    padding_side=\"left\",\n",
    "    add_eos_token=True,\n",
    "    add_bos_token=True,\n",
    "    use_fast=False,\n",
    "    token=access_token\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel\n",
    "\n",
    "ft_model = PeftModel.from_pretrained(model, \"gemma-2-it-emails/checkpoint-3000\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "iLrn4htyCTEm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos>\n",
      "  Give me an email-only content calendar for activating users that haven't used my service in more than 3 months.\n",
      "  The service is an online marketplace for prospective home buyers to find houses and apartments in the Netherlands.\n",
      "  Instructions: for each content idea provided, give me why this is something that makes sense for activating dormant users,\n",
      "  and how to adjust the content strategy depending on whether it has been successful at activating the user after each month.\n",
      "<eos><bos>1. **Welcome Email:**\n",
      " - Subject: Welcome to HomeFinds! Get a 100€ discount on your first search. 🏡 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 💰 \n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(\"\"\"\n",
    "  Give me an email-only content calendar for activating users that haven't used my service in more than 3 months.\n",
    "  The service is an online marketplace for prospective home buyers to find houses and apartments in the Netherlands.\n",
    "  Instructions: for each content idea provided, give me why this is something that makes sense for activating dormant users,\n",
    "  and how to adjust the content strategy depending on whether it has been successful at activating the user after each month.\n",
    "\"\"\",\n",
    "                   return_tensors=\"pt\", return_attention_mask=False).to(\"cuda\")\n",
    "\n",
    "outputs = ft_model.generate(**inputs, max_length=500)\n",
    "text = tokenizer.batch_decode(outputs)[0]\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LeYIdS61GF9q"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "05849d81ea3c476399fa16ed04df701e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "08d4c699bdac443cb2696a9016bab802": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cef43065c0cd4a58b04212cefd61106c",
      "placeholder": "​",
      "style": "IPY_MODEL_c200736bc07e4c35a95e8a923e225d28",
      "value": " 30132/30132 [00:15&lt;00:00, 2163.66 examples/s]"
     }
    },
    "11c77b811e0745569b4dc40685f71b6e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1a66559c14b14e86ac3e38581c87d773": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bf091b6addf846bf881bdddcaa1d292f",
       "IPY_MODEL_9ff5bf96034e4982be9a296658e18b28",
       "IPY_MODEL_08d4c699bdac443cb2696a9016bab802"
      ],
      "layout": "IPY_MODEL_48c3a62fa47a404ea92e1c17fc7b50eb"
     }
    },
    "1f2c71bf1e9348518fae1c087ffe1b72": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_905184dcef1f4df1b8568a6aa8d1882c",
      "placeholder": "​",
      "style": "IPY_MODEL_cb334193ef184a80ac76acafc42e9e15",
      "value": "Map: 100%"
     }
    },
    "27b71e0556d84b62ab024d6df25f5422": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "295cc2482da0441080cc3404f488d09c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_05849d81ea3c476399fa16ed04df701e",
      "max": 3349,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_11c77b811e0745569b4dc40685f71b6e",
      "value": 3349
     }
    },
    "36f6e9448580497bbfb47b2dde1e2bf4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3bcbf7ccbecb4b6aab73017ec7c6da05": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_75756ad6cd8c4556beb9bb1f36da3c84",
      "placeholder": "​",
      "style": "IPY_MODEL_5d792d0310e94385bd150658adf60c34",
      "value": " 3349/3349 [00:01&lt;00:00, 1912.59 examples/s]"
     }
    },
    "48c3a62fa47a404ea92e1c17fc7b50eb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5d792d0310e94385bd150658adf60c34": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5f462014cb824dea9bec2ae36f7f01ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1f2c71bf1e9348518fae1c087ffe1b72",
       "IPY_MODEL_295cc2482da0441080cc3404f488d09c",
       "IPY_MODEL_3bcbf7ccbecb4b6aab73017ec7c6da05"
      ],
      "layout": "IPY_MODEL_661fa7e195d844a482a212be4c4ee79c"
     }
    },
    "661fa7e195d844a482a212be4c4ee79c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "72bb036a5c264621b85589199debd8cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "75756ad6cd8c4556beb9bb1f36da3c84": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "905184dcef1f4df1b8568a6aa8d1882c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9ff5bf96034e4982be9a296658e18b28": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c2c7d284450841259db296c370886281",
      "max": 30132,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_36f6e9448580497bbfb47b2dde1e2bf4",
      "value": 30132
     }
    },
    "bf091b6addf846bf881bdddcaa1d292f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_27b71e0556d84b62ab024d6df25f5422",
      "placeholder": "​",
      "style": "IPY_MODEL_72bb036a5c264621b85589199debd8cf",
      "value": "Map: 100%"
     }
    },
    "c200736bc07e4c35a95e8a923e225d28": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c2c7d284450841259db296c370886281": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cb334193ef184a80ac76acafc42e9e15": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cef43065c0cd4a58b04212cefd61106c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
